My overall approach is to first get familiarized with HTML interactions then log into Fakebook with my credentials, and then refine my crawling algorithm to fetch out the flags. The biggest challenge for me in this project is logging in. I first read the curl library in Python and tried to log in with curl to see the server responses. After that, I know what I should expect from the server. I then hard-coded the login process without implementing status code handling(which I later realized was a big mistake). Once I got that working, I moved on to status code handling but I realized I had to change a lot of things. I had my login process written in the run method initially, and I had to move it over to the send_request method and add logic to handle logging in separately which was a pain. 
Testing log-in was fairly straightforward, I just printed out each request I sent to the server and each response server replied. However, testing the crawling was a lot harder than I thought. I tried to use the same printing mechanics but it didn't quit work since there are too many interactions. So I implemented more error handling to make sure I'm not in a loop or stuck in somewhere I shouldn't be. 